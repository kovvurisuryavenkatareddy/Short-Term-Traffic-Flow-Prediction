{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  BI-Directional Long Short Term Memory Model (BI-LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is Bi-Directional Lstm ?**\n",
    "- Bi-Directional LSTM is a type of Sequence Model that Consists of two LSTM Layers.\n",
    "- One Processes the  input in the forward Direction and the other processes it in the Backward Direction.\n",
    "The architecture of a Bi Directional LSTM  includes two Separate LSTM networks:\n",
    "\n",
    "**Forward LSTM:** \n",
    "- Process the Sequence from start to end.\n",
    "\n",
    "**Backward LSTM:** \n",
    "- Processes the Sequence from end to start.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Below are the Required Modules for this Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Models for the project\n",
    "\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as  np # type: ignore\n",
    "import os # type: ignore\n",
    "import math # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler # type: ignore\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model  # type: ignore\n",
    "from tensorflow.keras.layers import InputLayer, Bidirectional, LSTM, Dense # type: ignore\n",
    "from tensorflow.keras.losses import MeanSquaredError # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to load our dataset required for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'PATH_TO_YOUR_DATASET.csv' # Path to your dataset\n",
    "dataset = pd.read_csv(file_path) # Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure There is no zero values in the dataset,we have to check is there any null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = dataset.isnull().sum() # Check for null values in the dataset\n",
    "print(\"Null values in each column:\\n\", null_values) # Print the null values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, We have to get the required data values in between 0 and 1 to make the caculations simpler.\n",
    "\n",
    "So, we are using the Normalizatioin Method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['Column Name'] # Column name to be normalized\n",
    "scaler = MinMaxScaler() # Normalizing the data\n",
    "dataset[column] = scaler.fit_transform(dataset[column]) # Normalizing the data\n",
    "dataset.head() # Displaying the first 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to divide the data into the sequences according to the required number of TimeIntervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences\n",
    "\n",
    "def create_sequences(column_data, time_steps):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(column_data) - time_steps):\n",
    "        X.append(column_data[i:i + time_steps])\n",
    "        Y.append(column_data[i + time_steps])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_data = dataset[['Column_Name']].values\n",
    "time_steps = 'No_of_time_steps' # Number of time steps   \n",
    "input_dimension = 1 # Input dimension\n",
    "\n",
    "BI_LSTM_X, y = create_sequences(column_data, time_steps) # Creating sequences\n",
    "\n",
    "# Displaying the values of LSTM_X and y\n",
    "\n",
    "print(f\"Values of BI_LSTM_X: {BI_LSTM_X}\") \n",
    "print(f\"Values of y: {y}\")\n",
    "\n",
    "print(f\"Shape of BI_LSTM_X: {BI_LSTM_X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now , we have to split the data for training and testing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training top 90% and testing bottom 10%\n",
    "\n",
    "train_size = int(len(BI_LSTM_X) * 0.90) \n",
    "X_train, X_test = BI_LSTM_X[:train_size], BI_LSTM_X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Displaying the shapes of the training and testing data\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "print(\"Training X Values : \",X_train)\n",
    "print(\"Testing X Values : \",X_test)\n",
    "print(\"Training y Values : \",y_train)\n",
    "print(\"Testing y Values : \",y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI-LSTM Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create the BI-LSTM Model as we already imported the required modeules respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # Creating a Sequential model\n",
    "model.add(Bidirectional(LSTM('Number of Neurons Required', return_sequences=True), input_shape=(time_steps, 1))) # Adding a Bidirectional LSTM layer\n",
    "model.add(Bidirectional(LSTM('Number of Neurons Required', return_sequences=False))) # Adding a Bidirectional LSTM layer\n",
    "model.add(Dense('Number of Neurons Required', activation='relu')) # Adding a Dense layer\n",
    "model.add(Dense(1)) # Adding a Dense layer\n",
    "model.compile(optimizer='', loss='') # Compiling the model\n",
    "model.summary() # Displaying the model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created the model for the LSTM, Now we have to train the model by using the Training Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train, y_train,epochs='Number of Iterations', batch_size=32, validation_split=\"mention the validation split value\", verbose=1) # Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upto to this is the model creation and the model training.\n",
    "\n",
    "Let's Predict the values using the model we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(\"x_testing_data_values\") # Predicting the values\n",
    "train_prediction = scaler.inverse_transform(train_predictions).flatten() # Inverse transforming the predicted values\n",
    "\n",
    "y = scaler.inverse_transform(\"y_testing_data_values\".reshape(-1, 1)).flatten() # Inverse transforming the y values\n",
    "\n",
    "train_results = pd.DataFrame(data={'Train Predictions': train_prediction, 'Actuals': y}) # Creating a dataframe\n",
    "print(train_results)  # Displaying the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to save the moedel so we can load the model without re-training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"path_to_save_the_maodel\") # Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model(\"path_to_save_the_maodel\") # Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Values of the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now , we have to check the loss values of the Model we trained so we can get the  accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = math.sqrt(mean_squared_error(y, train_prediction))\n",
    "mae = mean_absolute_error(y, train_prediction)\n",
    "mape = mean_absolute_percentage_error(train_prediction, y)\n",
    "\n",
    "# Displaying the RMSE, MAE and MAPE values\n",
    "\n",
    "print('RMSE:', rmse)\n",
    "print('MAE:', mae)\n",
    "print('MAPE:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss  Graph for the model\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
